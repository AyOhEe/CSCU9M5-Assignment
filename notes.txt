This .txt file contains the rough contents for each section, before I made the poster.
I prefer writing my thoughts in text, but writing them in a file lets me keep this in version control.

Section 1:
3423815

Section 2:
[TODO progressively outline]
Test/train/validate: 65/17.5/17.5
This was done to ensure sufficient test and validation data at the end of training, as
the dataset is rather small at only 517 entries.

Performed histogram analysis and removed "rain" variable.
Configured orange workflow to train and test the three selected model types on the train 
and test datasets, and to display results on both the test and validation datasets.

Experimented with variations of hyperparameters for all three chosen model types,
eventually settling on Random Forest with n=25, threshold=5

Sequentially tested model performance when missing individual features to determine the 
importance of each feature on model performance.

Section 3:
- X: Discrete Feature - Used
- Y: Discrete Feature - Used
- Month: Categorical Feature - Used
- Day: Categorical Feature - Unused
- FFMC: Continuous Feature - Used
- DMC: Continuous Feature - Used
- DC: Continuous Feature - Used
- ISI: Continuous Feature - Used
- Temp: Continuous Feature - Used
- RH: Continuous Feature - Used
- Wind: Continuous Feature - Used
- Rain: Continuous Feature - Unused (due to histogram)
- Area: Categorical Target - Required.
TODO [explain consequence]
 - Something about assuming that the main correlation to be found in position will be identifying
   particularly well-burning "hot spots" for wildfires, and as such one-hot encoding will make more
   sense than continuous as the correlation is assumed to not be linear w.r.t. X or Y, but a
   combination involving both coordinates.
 - That isn't really a consequence. Think of something else?


Section 4:
The "rain" variable has a large majority value at 0, comprising almost all datapoints.
As such, this variable was not considered.

Section 5:
Model types used: Neural Network, Random forest, Support Vector Machine
All models were evaluated with 5-fold cross validation
Hyperparameters were chosen by modifying one parameter at a time from a set that had already been tested, such that a comparisson could be drawn.

Neural network hyperparameter experiments:
- CA = 0.733 @ [100,] with 500 iterations
- CA = 0.786 @ [100,100] with 500 iterations
- CA = 0.816 @ [100,100] with 1000 iterations
- CA = 0.843 @ [200, 100] with 1000 iterations
- CA = 0.807 @ [200, 100, 50] with 1000 iterations
- CA = 0.804 @ [200, 100, 50] with 2000 iterations
- CA = 0.816 @ [200, 100] with 2000 iterations
- CA = 0.763 @ [200, 200] with 1000 iterations
- CA = 0.780 @ [300, 100] with 1000 iterations
- CA = 0.777 @ [300, 100] with 2000 iterations
- CA = 0.772 @ [300, 200] with 3000 iterations
- CA = 0.825 @ [200, 100] with 1500 iterations

Best performing parameters: [200, 100] with 1000 iterations, for CA = 0.843


Random forest hyperparameter experiments:
- CA = 0.831 @ n=10, threshold=5
- CA = 0.846 @ n=20, threshold=5
- CA = 0.843 @ n=30, threshold=5
- CA = 0.858 @ n=25, threshold=5
- CA = 0.813 @ n=5, threshold=5
- CA = 0.834 @ n=25, threshold=8
- CA = 0.843 @ n=25, threshold=3

Best performing parameters: n=26, threshold=5, for CA = 0.858


SVM hyperparameter experiments:
- CA = 0.754 @ C=1.00, e=0.1, iterations=100
- CA = 0.751 @ C=1.00, e=0.1, iterations=200
- CA = 0.774 @ C=2.00, e=0.1, iterations=200
- CA = 0.766 @ C=2.00, e=0.1, iterations=100
- CA = 0.766 @ C=4.00, e=0.1, iterations=200
-----Switched to RBF-----
- CA = 0.804 @ C=2.00, e=0.1, iterations=200, g=auto, c=1.0, d=4
- CA = 0.804 @ C=2.00, e=0.1, iterations=300, g=auto, c=1.0, d=4
- CA = 0.813 @ C=2.00, e=0.1, iterations=300, g=auto, c=1.0, d=5
- CA = 0.783 @ C=2.00, e=0.1, iterations=300, g=auto, c=1.5, d=5
- CA = 0.769 @ C=2.00, e=0.1, iterations=300, g=auto, c=2.0, d=5

Best performing parameters: C=2.00, e=0.1, iterations=300, g=auto, c=1.0, d=5, for CA = 0.813


Final model chosen: The best model seems to be Random Forest, with a CA of 0.858 with n=25, threshold=5


Section 6:
Model choice justification: Random Forest was found to perform best on this problem after manual hyperparameter tuning, 
                            compared to an SVM or Neural Network. The neural network could not be manually improved above CA = 0.843,
                            nor could the SVM be manually improved above 0.813. The random forest model performed 1.5%pt. better than
                            the neural network model, and 4.5%pt. better than the SVM model.
Confusion matrix on test dataset: 
        Predicted
        F      T
A
c  F    35     1
t
u
a  T    8      46
l

Comment: The confusion matrix tells us that the model is quite accurate (CA = 0.856 on test data), and has a low rate of false-positives, 
         but a higher rate of false-negatives. This suggests that the model is useful and fairly reliable, but that it is advisable to lean on the
         side of caution when using its predictions.


Section 7:
By removing individual features, we can get a picture of which features are most relevant to the model as it forms its prediction. [TODO fill process]
- Base classification accuracy: CA = 0.858
- Without X:                    CA = 0.843
- Without Y:                    CA = 0.852
- Without Month:                CA = 0.810
- Without FFMC:                 CA = 0.840
- Without DMC:                  CA = 0.813
- Without DC:                   CA = 0.810
- Without ISI:                  CA = 0.846
- Without Temp:                 CA = 0.828
- Without RH:                   CA = 0.846
- Without Wind:                 CA = 0.846
This suggests that the month, duff moisture code (DMC), and the drought code (DC) are particularly important features, as the model performed
significantly worse (up to 4.8%pt worse) when it did not have access to this information. Similarly, rather intuitively, but less extensively, 
temperature seems to be an important feature, as he model performed 3.0%pt worse when lacking the temperature information.

The model is clearly biased towards predicting "T", reflecting the larger amount of "T" entries in the dataset.
The nature of a random forest model is that it conglomerates the prediction of multiple decision trees. This makes it difficult towards
fully grasp the decision-making process that occurs inside the model. While it is theoretically possible to reason through each tree and
determine why it may have come to a given decision, to most people (especially those outside of mathematics or computing science), it
is functionally a "black box".

Section 8:
[TODO convert to IEEE] Canvas materials by Sandy Brownlee
[TODO convert to IEEE] Lecture slides by Ashan Adeel and Hazrat Ali